{
  "tests": [
    {
      "name": "basic_inference_test",
      "input": {
        "prompt": "Write a short poem about artificial intelligence.",
        "sampling_params": {
          "max_tokens": 100,
          "temperature": 0.7
        }
      },
      "timeout": 120000
    },
    {
      "name": "openai_chat_completions_test",
      "input": {
        "openai_route": "/v1/chat/completions",
        "openai_input": {
          "model": "HuggingFaceTB/SmolLM2-135M-Instruct",
          "messages": [
            {
              "role": "system",
              "content": "You are a helpful assistant that writes concise responses."
            },
            {
              "role": "user",
              "content": "Explain what a neural network is in one sentence."
            }
          ],
          "max_tokens": 200,
          "temperature": 0.1
        }
      },
      "timeout": 120000
    },
    {
      "name": "openai_models_list_test",
      "input": {
        "openai_route": "/v1/models",
        "openai_input": {}
      },
      "timeout": 30000
    },
    {
      "name": "streaming_test",
      "input": {
        "openai_route": "/v1/chat/completions",
        "openai_input": {
          "model": "HuggingFaceTB/SmolLM2-135M-Instruct",
          "messages": [
            {
              "role": "user",
              "content": "Count from 1 to 5."
            }
          ],
          "max_tokens": 50,
          "temperature": 0,
          "stream": true
        }
      },
      "timeout": 120000
    }
  ],
  "config": {
    "gpuTypeId": "NVIDIA GeForce RTX 4090",
    "gpuCount": 1,
    "env": [
      {
        "key": "MODEL_NAME",
        "value": "HuggingFaceTB/SmolLM2-135M-Instruct"
      },
      {
        "key": "MAX_MODEL_LEN",
        "value": "2048"
      }
    ],
    "allowedCudaVersions": ["12.4", "12.5", "12.6", "12.7", "12.8", "12.9"]
  }
}
